# -*- coding: utf-8 -*-
"""biRNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XBmicT2O8KSJxn2ia83j8TJHlUu-_v6q
"""

!pip3 install -q keras



# Chang Kim, Bryan Tor, Carson Burr
import pandas as pd
import numpy as np
from tensorflow.python.keras.preprocessing.text import Tokenizer
from tensorflow.python.keras.preprocessing.sequence import pad_sequences
from tensorflow.python.keras.models import Sequential, load_model
from tensorflow.python.keras.layers import Dense, Embedding, LSTM, Bidirectional
from tensorflow.python.keras.optimizers import Nadam
import tensorflow as tf
import os
TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR'] # FOR USE ON GOOGLE CLOUD

def main():
    df = pd.read_csv('https://raw.githubusercontent.com/cnk113/sentiment-analysis-on-movie-reviews/master/train.csv')
    y = df['Sentiment'] # Labels
    tokenizer = Tokenizer(num_words=400)
    tokenizer.fit_on_texts(df['Phrase'].values)
    X = tokenizer.texts_to_sequences(df['Phrase'].values)
    max_words = 400
    embed_dim = 128
    lstm_out = 256
    X = pad_sequences(X, max_words)
    model = Sequential()
    model.add(Embedding(max_words, embed_dim, input_length = X.shape[1]))
    model.add(Bidirectional(LSTM(lstm_out, recurrent_dropout=0.3, dropout=0.2)))
    model.add(Dense(5,activation='softmax'))
    model.compile(loss = 'categorical_crossentropy', optimizer='Nadam', metrics = ['acc'])
    print(model.summary())
    tpu_model = tf.contrib.tpu.keras_to_tpu_model(model,strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))
    batch_size = 32
    tpu_model.fit(X, pd.get_dummies(y).values, epochs=11, batch_size=batch_size, validation_split=0.2)
    model.save('RNN')

if __name__ == "__main__":
    main()



